BUBBLE SORT (SINKING SORT)
    ->requires very less space memory
    ->best case being O(n) it is beneficial in determining that array is sorted or not

    ->it is inefficient for large data as the worst time case being O(n^2)

    ->time complexity = O(n^2)
    ->space complexity = O(1)

INSERTION SORT 
    ->picks one element at a time and place it in the correct position of the sorted array
    ->efficient for small data
    ->adaptive in nature that is it is appropriate for data sets which are already partially sorted

    ->insertion sort takes maximum time if the elements are sorted in reverse order

    ->time complexity O(n^2)
    ->space complexity O(1)

SELECTION SORT
    ->selects the smallest element from the unsorted array in each iteration and places that in the begining of the array.
    ->it maintains two subarray
        ->one which is sorted
        ->one which is not sorted
    
    ->time complexity O(n^2)
    ->space complexity O(1)


MERGE SORT
    ->its consider an example of divide and conquer technique
    ->it is a recursive algorithm 
    ->in this array is divided into subarray till it cannot be divided into further smaller subarray 
        i.e till only single elements is not left then the dividing will stop
    ->finally when both halves are in a sorted order they are merged together by taking two different subarray and merging them 


    ->slower comparative to the other sorting algorithm for smaller takes
    ->requires additional memory space O(n) for the temporary array
    ->it goes through the whole process even if the array is sorted

    ->time complexity O(n logn)
    ->space complexity O(n)


QUICK SORT
    ->just like merge sort it is also a divide and conquer algorithm
    ->it picks an element as a pivot and partitions the given array around the picked pivot
    ->the key process of quick sort is partitions
    ->place the pivot element in its correct position and all the smaller element before it 
    ->and ahead of the pivot being greater elements than the pivot
    ->keep dividing till we cannot divide the subarray further that is single element is reached



    ->TO SELECT PIVOT=========================================
        ->Always pick the first element as a pivot.
        ->Always pick the last element as a pivot 
        ->Pick a random element as a pivot.
        ->Pick median as the pivot.

    ->time complexity o(n logn)
    ->space complexity o(1)
     
COUNT SORT
    ->based on keys between a specific range.
    ->works by counting the number of distinct key values (kind of hashing)
    ->it makes assumption about the data that the value will be in the given range of key values
    ->unlike other algorithms it is not a comparision algo rather it hashes the value in temporary array 
        and make it a non inplace algorithm.
    ->counting sort is efficient if the range of input data is not significantly greater than the number of objects to be sorted.
    ->it is a sub routine to another sorting algorithms like radix sort

    ->time complexity O(n+k)
    ->space complexity O(n+k)


HEAP SORT
    ->it is a comparision based sorting algorithm
    ->it is similar to selection sort where we select the minimum element and place it in the begining.
    ->repeat the same process for rest of the elements.
    ->it is an unstable sorting algorithm
    ->time required to perform heap sort is increased logarithmically while other grow exponentially
    ->memory usage is minimal
    ->mainly used in hybrid algorithms like intro sort

    ->has limited use as quick sort and merge sort are better in practice

    ->time complexity O(n logn)
    ->space complexity O(1)


RADIX SORT - https://www.geeksforgeeks.org/radix-sort/
SHELL SORT - https://www.geeksforgeeks.org/shellsort/
COMB SORT - https://www.geeksforgeeks.org/comb-sort/
PIGEONHOLE SORT - https://www.geeksforgeeks.org/pigeonhole-sort/